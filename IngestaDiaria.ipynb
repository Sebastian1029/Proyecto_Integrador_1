{"cells": [{"metadata": {"trusted": true}, "id": "f84f6d51", "cell_type": "code", "source": "! pip install boto3\n! pip install paramiko\n! pip install pysftp\n\n", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: boto3 in /opt/conda/lib/python3.9/site-packages (1.28.17)\nCollecting botocore<1.32.0,>=1.31.17 (from boto3)\n  Obtaining dependency information for botocore<1.32.0,>=1.31.17 from https://files.pythonhosted.org/packages/3d/4c/8f97418ad082458a0d8e6d10434227d54edc6166e3197cee6ecf7b0eeec0/botocore-1.31.85-py3-none-any.whl.metadata\n  Downloading botocore-1.31.85-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.9/site-packages (from boto3) (0.10.0)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from boto3) (0.6.2)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.9/site-packages (from botocore<1.32.0,>=1.31.17->boto3) (2.8.2)\nRequirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.9/site-packages (from botocore<1.32.0,>=1.31.17->boto3) (1.26.16)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.17->boto3) (1.16.0)\nDownloading botocore-1.31.85-py3-none-any.whl (11.3 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: botocore\n  Attempting uninstall: botocore\n    Found existing installation: botocore 1.20.106\n    Uninstalling botocore-1.20.106:\n      Successfully uninstalled botocore-1.20.106\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\naiobotocore 2.6.0 requires botocore<1.31.18,>=1.31.17, but you have botocore 1.31.85 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed botocore-1.31.85\nCollecting paramiko\n  Obtaining dependency information for paramiko from https://files.pythonhosted.org/packages/ad/50/8792484502c8141c20c996b802fefa8435a9c018a2bb440a06b172782118/paramiko-3.4.0-py3-none-any.whl.metadata\n  Downloading paramiko-3.4.0-py3-none-any.whl.metadata (4.4 kB)\nCollecting bcrypt>=3.2 (from paramiko)\n  Obtaining dependency information for bcrypt>=3.2 from https://files.pythonhosted.org/packages/97/00/21e34b365b895e6faf9cc5d4e7b97dd419e08f8a7df119792ec206b4a3fa/bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata\n  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\nRequirement already satisfied: cryptography>=3.3 in /opt/conda/lib/python3.9/site-packages (from paramiko) (38.0.4)\nCollecting pynacl>=1.5 (from paramiko)\n  Obtaining dependency information for pynacl>=1.5 from https://files.pythonhosted.org/packages/ee/87/f1bb6a595f14a327e8285b9eb54d41fef76c585a0edef0a45f6fc95de125/PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata\n  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.9/site-packages (from cryptography>=3.3->paramiko) (1.14.5)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=3.3->paramiko) (2.21)\nDownloading paramiko-3.4.0-py3-none-any.whl (225 kB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m225.9/225.9 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: bcrypt, pynacl, paramiko\nSuccessfully installed bcrypt-4.1.3 paramiko-3.4.0 pynacl-1.5.0\nCollecting pysftp\n  Downloading pysftp-0.2.9.tar.gz (25 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: paramiko>=1.17 in /opt/conda/lib/python3.9/site-packages (from pysftp) (3.4.0)\nRequirement already satisfied: bcrypt>=3.2 in /opt/conda/lib/python3.9/site-packages (from paramiko>=1.17->pysftp) (4.1.3)\nRequirement already satisfied: cryptography>=3.3 in /opt/conda/lib/python3.9/site-packages (from paramiko>=1.17->pysftp) (38.0.4)\nRequirement already satisfied: pynacl>=1.5 in /opt/conda/lib/python3.9/site-packages (from paramiko>=1.17->pysftp) (1.5.0)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.9/site-packages (from cryptography>=3.3->paramiko>=1.17->pysftp) (1.14.5)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=3.3->paramiko>=1.17->pysftp) (2.21)\nBuilding wheels for collected packages: pysftp\n  Building wheel for pysftp (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pysftp: filename=pysftp-0.2.9-py3-none-any.whl size=15496 sha256=471eb3ade950d8074f90004bce14ef231a80460f045785eea05d6f5fe88a3fea\n  Stored in directory: /home/jovyan/.cache/pip/wheels/0c/0e/4e/b8c1140f0fdcfb73bafe525942bff85043231e6787b7eab72c\nSuccessfully built pysftp\nInstalling collected packages: pysftp\nSuccessfully installed pysftp-0.2.9\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "id": "5b2fdb9f", "cell_type": "code", "source": "import pysftp\nimport boto3 \nimport os", "execution_count": 3, "outputs": []}, {"metadata": {"scrolled": true, "trusted": true}, "id": "8b68d448", "cell_type": "code", "source": "# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Tue Apr  9 16:15:24 2024\n \n@author: drangeve\n\"\"\"\nimport pandas as pd\nfrom datetime import datetime, timedelta, date\nimport paramiko\n\nimport os\n\nimport io\n#import csv\n ", "execution_count": 10, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "header = ['DESTINO',\n          'TIPO_PRUEBA',\n          'IP_VERSION',\n          'MEDIDA',\n          'VALOR',\n          'UNIDAD_MEDIDA',\n          'FECHA',\n          'SEMANA',\n          'DEVICE_UUID',\n          'DEVICE_NAME',\n          'CONTEXT']", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "id": "db80369b", "cell_type": "code", "source": "\n###############################################################################\nbucket = 'pisemestre1'\ns3 = boto3.client('s3')\n\nhostname = 'transfer.tigo.com.co'\nport = 2222\nusername = 'inspector11'\npassword = 'Pongame5enlamateria+++'\n ", "execution_count": 11, "outputs": []}, {"metadata": {"trusted": true}, "id": "b0cbd7ff", "cell_type": "code", "source": "\n###############################################################################\n \ndesired_year = '2024'\ndesired_month = '06'", "execution_count": 12, "outputs": []}, {"metadata": {"trusted": true}, "id": "abdc5109", "cell_type": "code", "source": "\n \n###############################################################################\n \nremote_dir = f'/INSPECTOR01/{desired_year}/{desired_month}'\nlocal_dir = f'raw/{desired_year}_{desired_month}'\n", "execution_count": 13, "outputs": []}, {"metadata": {"trusted": true}, "id": "a3ac292e", "cell_type": "code", "source": "\n################################################################################## \ntransport = paramiko.Transport((hostname, port))\ntransport.connect(username=username, password=password)\n \n# Create SFTP session\nsftp = paramiko.SFTPClient.from_transport(transport)\n ", "execution_count": 9, "outputs": []}, {"metadata": {"trusted": false}, "id": "2b35d56e", "cell_type": "code", "source": "cont = 0\ntoday = date.today()\n# Loop through subdirectories starting with \"semana_xx\"\nfor subdir_attr in sftp.listdir_attr(remote_dir):\n    subdir = subdir_attr.filename\n    last_modified_time = datetime.fromtimestamp(subdir_attr.st_mtime)\n    \n    if subdir.startswith(\"semana_\") and last_modified_time.date()==today:\n        # Download CSV files with prefix directly to local directory\n        for filename_attr in sftp.listdir_attr(f\"{remote_dir}/{subdir}\"):\n            filename=filename_attr.filename\n            Last_Mod=datetime.fromtimestamp(filename_attr.st_mtime)\n    \n            if filename.endswith(\".csv\") and Last_Mod.date()==today:\n                local_filename = f\"{subdir}+{filename}\"\n                sftp.get(f\"{remote_dir}/{subdir}/{filename}\", local_filename)\n                \n                s3_name = f\"{local_dir}/{local_filename}\"\n                #print(f\"Downloaded: {s3_name}\")\n                \n              \n                try:\n                    s3.upload_file(local_filename,bucket,s3_name)\n                    print(f\"Downloaded: {s3_name}\")\n                except:\n                    print('Error all cargar')\n                    \n                    \n                    \"\"\"\n                    with sftp.file(remote_file_path, 'r') as remote_file:\n                    file_content = remote_file.read().decode('utf-8')\n\n                    # Convertir el contenido del archivo a un DataFrame\n                    csv_buffer = io.StringIO(file_content)\n                    df = pd.read_csv(csv_buffer)\n                    \"\"\"\n               \n", "execution_count": 27, "outputs": [{"output_type": "stream", "text": "Downloaded: raw/2024_06/semana_23+a81b9c24985a885afa112df647c67839.csv\nDownloaded: raw/2024_06/semana_23+07082e0c5c9d3c7a0209c224c3460c4e.csv\nDownloaded: raw/2024_06/semana_23+d23a3aa9c1f7e0789f31b8f6eb018467.csv\n", "name": "stdout"}]}, {"metadata": {"trusted": false}, "id": "d3c67f92", "cell_type": "code", "source": " \n# Close connection\nsftp.close()\ntransport.close()\n ", "execution_count": 22, "outputs": []}, {"metadata": {"trusted": false}, "id": "89873d28", "cell_type": "code", "source": "def trustifyer(df_aux, trusted_path, header,s3):\n    \n    columnas_utiles = [\n                'TIPO_PRUEBA',\n                'IP_VERSION',\n                'MEDIDA',#'estadistica',\n                'DESTINO',#'medicion',\n                'VALOR',#'valor',         \n                'FECHA',#'fecha',              \n                'DEVICE_UUID',#'device',\n                'DEVICE_NAME'#'devicename'  \n                ]\n    \n    \n\n    #df_aux= pd.read_csv(data,names=header, low_memory=False, encoding='latin1',\n                             usecols = columnas_utiles\n                             )\n    df_aux = df_aux[\n                (df_aux['DESTINO'].isin(['google.com', 'youtube.com'])) &\n                (df_aux['TIPO_PRUEBA'] == 'Ping') &\n                (df_aux['IP_VERSION'] == 'IPv4') &\n                (df_aux['MEDIDA'].isin(['avg', 'packet_loss']))\n            ]\n\n        #break    \n    df_aux['VALOR'] = df_aux['VALOR'].astype(float)\n\n    print('carga exitosa de semanas')   \n                   \n    df = df_aux\n \n    del df_aux\n    #zzz=list(Counter(df['CONTEXT']).keys())\n    #del dict_df_raw\n    #print('0')#######################################################################################################\n    \n    df['COL_KEY']= df['IP_VERSION'].fillna('TBD') + '_' + df['DESTINO'].fillna('TBD') + '_' + df['MEDIDA'].fillna('TBD')+  '_' +df['DEVICE_UUID'].fillna('TBD')\n    print('creacion columna llave exitoso')\n    #print('0')#######################################################################################################\n\n    \n    #df = df[columnas_utiles]        \n    df['FECHA']=pd.to_datetime(df['FECHA'])\n    df['FECHA'] = df['FECHA'].dt.round('30min')        \n    print('remuestreo fechas exitoso')\n    \n    \n    #df_cnt = df[(df['DESTINO']=='google.com') & (df['MEDIDA']=='avg') & (df['IP_VERSION'].str.contains('IPv4', case=False))]\n    #len(list(set(df_cnt['DEVICE_NAME'])))\n###############################################################################\n###############################################################################\n###############################################################################\n###############################################################################\n###############################################################################\n###############################################################################\n    #print('0')#####################################################################################################\n    dict_1 = {\n        'col_key': 'COL_KEY',\n        'estadistica': 'MEDIDA',\n        'medicion': 'DESTINO',\n        'valor': 'VALOR',\n        'fecha': 'FECHA',\n        'device': 'DEVICE_UUID',\n        'devicename': 'DEVICE_NAME'\n    }\n    dict_2 = {\n        'COL_KEY': 'col_key',\n        'MEDIDA': 'estadistica',\n        'DESTINO': 'medicion',\n        'VALOR': 'valor',\n        'FECHA': 'fecha',\n        'DEVICE_UUID': 'device',\n        'DEVICE_NAME': 'devicename'\n    }\n###############################################################################\n###############################################################################\n###############################################################################\n###############################################################################\n###############################################################################\n###############################################################################\n\n#dataframe.rename(columns=column_mapping)\n    #print('---')#####################################################################################################\n    df = df.rename(columns = dict_2)   \n    \n    \n    \n    dict_df = {}\n    \n    for i in (list(set(list(df['col_key'])))):\n        #print('entr\u00e9 al for')\n        df_aux=df[df['col_key']==i].reset_index(drop = True)\n        #print('1')\n        if df_aux['estadistica'].iloc[0] in [ 'upload_speed',\n                                     'download_latency',\n                                     'HTTP_Time_Total',\n                                     'HTTP_Time_Connect',\n                                     'HTTP_Time_Start_Transfer',\n                                     'mravg',\n                                     'HTTP_Time_Redirect',\n                                     'HTTP_Time_Name_Lookup',\n                                     'HTTP_Time_Handshake',\n                                     'HTTP_Time_Pretransfer',\n                                     'HTTP_Size_Download',\n                                     'download_jitter',\n                                     'download_speed',\n                                     'avg',\n                                     'Query_Time']:\n            \n            def valor(series):\n                return series.iloc[0]\n    \n            df_aux = df_aux.groupby('fecha').agg({\n                'valor': [('mean_valor', 'mean'), ('std_valor', 'std')],\n                \n                'col_key': valor,\n                'medicion': valor,\n                'estadistica': valor,\n                'device': valor,\n                'devicename': valor\n            })\n            df_aux.reset_index(inplace=True)\n            # Flatten the column names\n            df_aux.columns = [''.join(col).strip() for col in df_aux.columns.values]\n            df_aux.columns = [col.replace('_valor', '').strip() for col in df_aux.columns]\n            df_aux.columns = [col.replace('valor', '').strip() for col in df_aux.columns]\n            df_aux.rename(columns={'mean': 'valor'}, inplace=True)\n            \n        #print('2')\n        if df_aux['estadistica'].iloc[0] in [ 'DNS_Response',\n                                             'HTTP_Code',\n                                             'HTTP_SSL_Verify']:\n            \n            def mode_value(series):\n                return series.mode().iloc[0]\n    \n            def std_value(series):\n                return 0\n            \n            def valor(series):\n                return series.iloc[0]\n            '''\n            result = df_aux.groupby('fecha').agg({\n                'valor': [('mean_valor', mode_value)],\n                'col_key': valor,\n                'medicion': valor,\n                'estadistica': valor,\n                'device': valor,\n                'devicename': valor\n            })\n            '''\n            df_aux.columns = [''.join(col).strip() for col in df_aux.columns.values]\n            df_aux.columns = [col.replace('_valor', '').strip() for col in df_aux.columns]\n            df_aux.columns = [col.replace('valor', '').strip() if col != 'valor' else col for col in df_aux.columns]\n            df_aux['std']=0      \n        #print('3')    \n        if df_aux['estadistica'].iloc[0] in ['packet_loss']:\n            \n            def valor(series):\n                return series.iloc[0]\n    \n            df_aux = df_aux.groupby('fecha').agg({\n                'valor': [('mean_valor', 'mean')],\n                \n                'col_key': valor,\n                'medicion': valor,\n                'estadistica': valor,\n                'device': valor,\n                'devicename': valor\n            })\n    \n            # Flatten the column names\n            df_aux.reset_index(inplace=True)\n            df_aux.columns = [''.join(col).strip() for col in df_aux.columns.values]\n            df_aux.columns = [col.replace('_valor', '').strip() for col in df_aux.columns]\n            #df_aux.columns = [col.replace('valor', '').strip() for col in df_aux.columns]\n            df_aux.columns = [col.replace('valor', '').strip() if col != 'valor' else col for col in df_aux.columns]\n            df_aux['std']=0\n            df_aux.rename(columns={'mean': 'valor'}, inplace=True)\n        #print('4')    \n        if df_aux['estadistica'].iloc[0] in ['min']:\n            \n            def min_value(series):\n                return series.min()\n            \n            def valor(series):\n                return series.iloc[0]\n    \n            df_aux = df_aux.groupby('fecha').agg({\n                'valor': [('mean_valor', min_value), ('std_valor', std_value)],\n                'col_key': valor,\n                'medicion': valor,\n                'estadistica': valor,\n                'device': valor,\n                'devicename': valor\n            })\n    \n            # Flatten the column names\n            df_aux.columns = [''.join(col).strip() for col in df_aux.columns.values]\n            df_aux.columns = [col.replace('_valor', '').strip() for col in df_aux.columns]\n            #df_aux.columns = [col.replace('valor', '').strip() for col in df_aux.columns]\n            df_aux.columns = [col.replace('valor', '').strip() if col != 'valor' else col for col in df_aux.columns]\n            df_aux['std']=0\n            df_aux.rename(columns={'mean': 'valor'}, inplace=True)\n        #print('5')    \n        if df_aux['estadistica'].iloc[0] in ['max']:\n            \n            def std_value(series):\n                return 0\n            \n            def max_value(series):\n                return series.max()\n            \n            def valor(series):\n                return series.iloc[0]\n    \n            df_aux = df_aux.groupby('fecha').agg({\n                'valor': [('mean_valor', max_value)],\n                'col_key': valor,\n                'medicion': valor,\n                'estadistica': valor,\n                'device': valor,\n                'devicename': valor\n            })\n    \n            # Flatten the column names\n            df_aux.columns = [''.join(col).strip() for col in df_aux.columns.values]\n            df_aux.columns = [col.replace('_valor', '').strip() for col in df_aux.columns]\n            #df_aux.columns = [col.replace('valor', '').strip() for col in df_aux.columns]\n            df_aux.columns = [col.replace('valor', '').strip() if col != 'valor' else col for col in df_aux.columns]\n            df_aux['std']=0\n            df_aux.rename(columns={'mean': 'valor'}, inplace=True)\n            \n            #break###############################################################################################\n        #print('6')    \n        dict_df[i] = df_aux\n    df_final = pd.concat(dict_df.values(), ignore_index=True)\n    csv_buffer = StringIO()\n\n    df_final = df_final.rename(columns = dict_1)  \n    \n    bucket_name = 'pisemestre1'\n    prefix = trusted_path\n\n\n# Iterar sobre todos los archivos en la carpeta especificada\n    response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n    for obj in response.get('Contents', []):\n        key = obj['Key']\n        if key.endswith('.csv'):\n            print(key)\n            csv_obj = s3.get_object(Bucket=bucket_name, Key=key)\n            body = csv_obj['Body']\n            csv_string = body.read().decode('latin1')\n            data = StringIO(csv_string)\n            Tru= pd.read_csv(data,names=df_final.columns,\n                                     usecols =df_final.columns\n                                     )\n    df_final=pd.concat(Tru,df_final)\n    df_final.to_csv(csv_buffer, index=False)\n    \n    s3.put_object(Bucket='pisemestre1', Key=f'{trusted_path}/trusted.csv', Body=csv_buffer.getvalue())\n\n    ", "execution_count": 9, "outputs": []}, {"metadata": {"trusted": false}, "id": "4b5bfe5c", "cell_type": "code", "source": "\n", "execution_count": 19, "outputs": [{"output_type": "stream", "text": "Archivo: semana_23, \u00daltima modificaci\u00f3n: 2024-06-12\n", "name": "stdout"}]}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "version": "3.9.5", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 5}